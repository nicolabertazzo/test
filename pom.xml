<?xml version='1.0' encoding='UTF-8'?>
<project xsi:schemaLocation="http://maven.apache.org/POM/4.0.0 http://maven.apache.org/xsd/maven-4.0.0.xsd" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns="http://maven.apache.org/POM/4.0.0">
    <modelVersion>4.0.0</modelVersion>
    <groupId>it.eng</groupId>
    <artifactId>exabeat_${scala.binary.version}</artifactId>
    <packaging>pom</packaging>
    <description>exabeat</description>
    <version>0.0.1-SNAPSHOT</version>
    <name>exabeat</name>
    <organization>
        <name>it.eng</name>
    </organization>
    
    <properties>
	    <scala.binary.version>2.10</scala.binary.version>
	    <scala.version>2.10.6</scala.version>
	    <java.version>1.7</java.version>
	    <spark.version>1.6.1</spark.version>
	    <hadoop.version>2.6.0</hadoop.version>
	    <hbase.version>1.0.3</hbase.version>
	    <project.build.sourceEncoding>UTF-8</project.build.sourceEncoding>
  	</properties>
    <build>
    	<plugins>
     		<plugin>
        		<groupId>net.alchim31.maven</groupId>
        		<artifactId>scala-maven-plugin</artifactId>
        		<version>3.2.1</version>
        		<executions>
          			<execution>
            			<goals>
              				<goal>compile</goal>
              				<goal>testCompile</goal>
            			</goals>
          			</execution>
        		</executions>
        		<configuration>
          			<scalaVersion>${scala.version}</scalaVersion>
        		</configuration>
      		</plugin>
      		<plugin>
	        	<groupId>org.scalatest</groupId>
	        	<artifactId>scalatest-maven-plugin</artifactId>
	        	<version>1.0</version>
	        	<configuration>
	          		<reportsDirectory>${project.build.directory}/surefire-reports</reportsDirectory>
	          		<junitxml>.</junitxml>
	          		<filereports>mvn_test_report.txt</filereports>
	        	</configuration>
	        	<executions>
		          	<execution>
		            	<id>test</id>
		            	<goals>
		              		<goal>test</goal>
		            	</goals>
		          	</execution>
	        	</executions>
	      	</plugin>
	      	<plugin>
        		<groupId>org.apache.maven.plugins</groupId>
        		<artifactId>maven-surefire-plugin</artifactId>
        		<version>2.7</version>
        		<configuration>
            	</configuration>
      		</plugin>
      	</plugins>
    </build>
    
    <modules>
	    <module>core</module>
	    <module>startkit</module>
  	</modules>
  	
    <dependencies>
        <dependency>
            <groupId>org.scala-lang</groupId>
            <artifactId>scala-library</artifactId>
            <version>${scala.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-core_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-sql_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <scope>provided</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.spark</groupId>
            <artifactId>spark-streaming-kafka_${scala.binary.version}</artifactId>
            <version>${spark.version}</version>
            <exclusions>
                <exclusion>
                    <groupId>log4j</groupId>
                    <artifactId>log4j</artifactId>
                </exclusion>
                <exclusion>
                    <groupId>org.spark-project.spark</groupId>
                    <artifactId>unused</artifactId>
                </exclusion>
            </exclusions>
        </dependency>
        <dependency>
            <groupId>com.databricks</groupId>
            <artifactId>spark-csv_${scala.binary.version}</artifactId>
            <version>1.4.0</version>
        </dependency>
        <dependency>
            <groupId>com.databricks</groupId>
            <artifactId>spark-xml_${scala.binary.version}</artifactId>
            <version>0.3.2</version>
        </dependency>
        <dependency>
            <groupId>it.nerdammer.bigdata</groupId>
            <artifactId>spark-hbase-connector_${scala.binary.version}</artifactId>
            <version>1.0.2</version>
        </dependency>
        <dependency>
            <groupId>org.scalatest</groupId>
            <artifactId>scalatest_${scala.binary.version}</artifactId>
            <version>2.2.6</version>
            <scope>test</scope>
        </dependency>
        <dependency>
            <groupId>org.apache.hadoop</groupId>
            <artifactId>hadoop-minicluster</artifactId>
            <version>${hadoop.version}</version>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-server</artifactId>
            <version>${hbase.version}</version>
            <type>test-jar</type>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-hadoop-compat</artifactId>
            <version>${hbase.version}</version>
            <scope>test</scope>
            <type>test-jar</type>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-hadoop2-compat</artifactId>
            <version>${hbase.version}</version>
            <scope>test</scope>
            <type>test-jar</type>
        </dependency>
        <dependency>
            <groupId>org.apache.hbase</groupId>
            <artifactId>hbase-server</artifactId>
            <version>${hbase.version}</version>
            <scope>test</scope>
        </dependency>
        

    </dependencies>
</project>